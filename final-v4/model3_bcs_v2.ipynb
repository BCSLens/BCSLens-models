{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d9949bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 34\n",
      "Entry 1: Missing image file: bcs_dataset/IMG_9099 - PANNAWAT SINTHUBTHONG.jpeg\n",
      "Entry 2: Missing image file: bcs_dataset/IMG_8980 - Patchareenat N.jpeg\n",
      "Entry 3: Missing view 0\n",
      "Entry 4: Missing image file: bcs_dataset/IMG_2570 - Pasavit TAPEN.jpeg\n",
      "Entry 5: Missing image file: bcs_dataset/IMG_0577 - Pakkaphan SAMAKWONGPANICH.jpeg\n",
      "Entry 6: Missing image file: bcs_dataset/IMG_2718 - Pasavit TAPEN.jpeg\n",
      "Entry 7: Missing image file: bcs_dataset/IMG_20250726_082932 - Khomson Satchasataporn.jpg\n",
      "Entry 8: Missing image file: bcs_dataset/IMG_20250726_083110 - Khomson Satchasataporn.jpg\n",
      "Entry 9: Missing image file: bcs_dataset/IMG_20250726_083323 - Khomson Satchasataporn.jpg\n",
      "Entry 10: Missing image file: bcs_dataset/IMG_20250726_084003 - Khomson Satchasataporn.jpg\n",
      "Entry 11: Missing image file: bcs_dataset/IMG_20250726_084722 - Khomson Satchasataporn.jpg\n",
      "Entry 12: Missing image file: bcs_dataset/IMG_20250726_084915 - Khomson Satchasataporn.jpg\n",
      "Entry 13: Missing image file: bcs_dataset/IMG_20250726_090443 - Khomson Satchasataporn.jpg\n",
      "Entry 15: Missing image file: bcs_dataset/IMG_20250726_091900 - Khomson Satchasataporn.jpg\n",
      "Entry 16: Missing image file: bcs_dataset/IMG_20250726_092105 - Khomson Satchasataporn.jpg\n",
      "Entry 17: Missing image file: bcs_dataset/IMG_20250726_092512 - Khomson Satchasataporn.jpg\n",
      "Entry 18: Missing image file: bcs_dataset/IMG_20250726_092852 - Khomson Satchasataporn.jpg\n",
      "Entry 19: Missing image file: bcs_dataset/IMG_20250726_094320 - Khomson Satchasataporn.jpg\n",
      "Entry 20: Missing image file: bcs_dataset/IMG_20250726_094713 - Khomson Satchasataporn.jpg\n",
      "Entry 21: Missing image file: bcs_dataset/IMG_20250726_095015 - Khomson Satchasataporn.jpg\n",
      "Entry 22: Missing image file: bcs_dataset/IMG_20250726_100103 - Khomson Satchasataporn.jpg\n",
      "Entry 23: Missing image file: bcs_dataset/IMG_20250726_100607 - Khomson Satchasataporn.jpg\n",
      "Entry 24: Missing image file: bcs_dataset/IMG_20250726_101251 - Khomson Satchasataporn.jpg\n",
      "Entry 25: Missing image file: bcs_dataset/IMG_20250726_102251 - Khomson Satchasataporn.jpg\n",
      "Entry 26: Missing image file: bcs_dataset/IMG_20250726_102757 - Khomson Satchasataporn.jpg\n",
      "Entry 27: Missing image file: bcs_dataset/IMG_20250726_103106 - Khomson Satchasataporn.jpg\n",
      "Entry 28: Missing image file: bcs_dataset/IMG_20250726_113405 - Khomson Satchasataporn.jpg\n",
      "Entry 29: Missing image file: bcs_dataset/IMG_20250726_113758 - Khomson Satchasataporn.jpg\n",
      "Entry 30: Missing image file: bcs_dataset/IMG_20250726_121135 - Khomson Satchasataporn.jpg\n",
      "Entry 31: Missing image file: bcs_dataset/IMG_20250726_122519 - Khomson Satchasataporn.jpg\n",
      "Entry 32: Missing image file: bcs_dataset/IMG_20250726_123603 - Khomson Satchasataporn.jpg\n",
      "Entry 33: Missing image file: bcs_dataset/IMG_20250726_130508 - Khomson Satchasataporn.jpg\n",
      "Successfully processed: 0 samples\n",
      "Skipped: 34 samples\n",
      "Final dataset shape: (0,)\n",
      "Labels shape: (0,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 119\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal dataset shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Check class distribution\u001b[39;00m\n\u001b[1;32m    122\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m Counter(y)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/_core/_methods.py:48\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Step 1: Load the JSON data\n",
    "with open('/Users/mjrchy/Documents/BCS-models-training-new-data/bcs_dataset_new.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Total entries: {len(data)}\")\n",
    "\n",
    "# Step 2: Process and validate data\n",
    "images = []\n",
    "bcs_labels = []\n",
    "skipped_count = 0\n",
    "\n",
    "for i, entry in enumerate(data):\n",
    "    # Check BCS value first\n",
    "    bcs_raw = entry.get(\"BCS\")\n",
    "    if bcs_raw is None or bcs_raw in ['ไม่ระบุ (ไม่ทราบ)', 'ไม่ระบุ', 'ไม่ทราบ']:\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Convert BCS to integer\n",
    "    try:\n",
    "        if isinstance(bcs_raw, (int, float)):\n",
    "            bcs_value = int(bcs_raw)\n",
    "        elif isinstance(bcs_raw, str) and bcs_raw.replace('.', '').isdigit():\n",
    "            bcs_value = int(float(bcs_raw))\n",
    "        else:\n",
    "            print(f\"Invalid BCS value: {bcs_raw}\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "    except (ValueError, TypeError):\n",
    "        print(f\"Could not convert BCS: {bcs_raw}\")\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Validate BCS range (1-9)\n",
    "    if bcs_value < 1 or bcs_value > 9:\n",
    "        print(f\"BCS out of range: {bcs_value}\")\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Collect all 4 view paths\n",
    "    views = [\n",
    "        entry.get(\"ภาพด้านบน (Top View)\"),\n",
    "        entry.get(\"ภาพด้านหลัง (Back View)\"),\n",
    "        entry.get(\"ภาพด้านขวา (Right View)\"),\n",
    "        entry.get(\"ภาพด้านซ้าย (Left View)\")\n",
    "    ]\n",
    "\n",
    "    # Load and validate images\n",
    "    img_list = []\n",
    "    valid = True\n",
    "    for j, v in enumerate(views):\n",
    "        if v is None:\n",
    "            print(f\"Entry {i}: Missing view {j}\")\n",
    "            valid = False\n",
    "            break\n",
    "        \n",
    "        path = os.path.join(\"bcs_dataset\", v)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Entry {i}: Missing image file: {path}\")\n",
    "            valid = False\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                print(f\"Entry {i}: Could not load image: {path}\")\n",
    "                valid = False\n",
    "                break\n",
    "            \n",
    "            # Resize to 224x224 for MobileNet\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            img_list.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Entry {i}: Error processing image {path}: {e}\")\n",
    "            valid = False\n",
    "            break\n",
    "    \n",
    "    if not valid:\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "\n",
    "    # Create 2x2 grid (448x448x3)\n",
    "    try:\n",
    "        top = np.concatenate([img_list[0], img_list[1]], axis=1)  # top row\n",
    "        bottom = np.concatenate([img_list[2], img_list[3]], axis=1)  # bottom row\n",
    "        combined = np.concatenate([top, bottom], axis=0)  # shape (448, 448, 3)\n",
    "        \n",
    "        images.append(combined)\n",
    "        bcs_labels.append(bcs_value - 1)  # Convert to 0-8 for model training\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Entry {i}: Error combining images: {e}\")\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Successfully processed: {len(images)} samples\")\n",
    "print(f\"Skipped: {skipped_count} samples\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(images, dtype=np.float32) / 255.0  # Normalize to [0,1]\n",
    "y = np.array(bcs_labels, dtype=np.int32)\n",
    "\n",
    "print(f\"Final dataset shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"Label range: {y.min()} to {y.max()}\")\n",
    "\n",
    "# Check class distribution\n",
    "class_counts = Counter(y)\n",
    "print(\"\\nClass distribution:\")\n",
    "for class_label in sorted(class_counts.keys()):\n",
    "    print(f\"BCS {class_label + 1}: {class_counts[class_label]} samples\")\n",
    "\n",
    "# Step 3: Ensure we have enough data\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"No valid samples found! Check your data and image paths.\")\n",
    "\n",
    "if len(np.unique(y)) < 2:\n",
    "    raise ValueError(\"Need at least 2 different classes for training.\")\n",
    "\n",
    "# Step 4: Custom train-test split to ensure all classes are represented\n",
    "class_indices = defaultdict(list)\n",
    "for idx, label in enumerate(y):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for class_label, indices in class_indices.items():\n",
    "    indices = shuffle(indices, random_state=42)\n",
    "    n_samples = len(indices)\n",
    "\n",
    "    if n_samples == 1:\n",
    "        # Only one sample → put it in both sets\n",
    "        train_indices.extend(indices)\n",
    "        test_indices.extend(indices)\n",
    "        print(f\"Warning: Only 1 sample for BCS {class_label + 1}, duplicating for train/test\")\n",
    "    else:\n",
    "        # At least 80% train, 20% test, but ensure at least 1 in each\n",
    "        n_test = max(1, int(0.2 * n_samples))\n",
    "        n_train = n_samples - n_test\n",
    "\n",
    "        if n_train == 0:\n",
    "            n_train = 1\n",
    "            n_test = n_samples - 1\n",
    "\n",
    "        train_indices.extend(indices[:n_train])\n",
    "        test_indices.extend(indices[n_train:])\n",
    "\n",
    "# Create train/test splits\n",
    "X_train, X_test = X[train_indices], X[test_indices]\n",
    "y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "print(f\"\\nTrain set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(\"Train class distribution:\", Counter(y_train))\n",
    "print(\"Test class distribution:\", Counter(y_test))\n",
    "\n",
    "# Step 5: Resize images to match MobileNet input (224x224)\n",
    "def resize_to_mobilenet_input(images):\n",
    "    \"\"\"Resize 448x448 images to 224x224 for MobileNet\"\"\"\n",
    "    resized = []\n",
    "    for img in images:\n",
    "        resized_img = cv2.resize(img, (224, 224))\n",
    "        resized.append(resized_img)\n",
    "    return np.array(resized, dtype=np.float32)\n",
    "\n",
    "X_train_resized = resize_to_mobilenet_input(X_train)\n",
    "X_test_resized = resize_to_mobilenet_input(X_test)\n",
    "\n",
    "print(f\"Resized train shape: {X_train_resized.shape}\")\n",
    "print(f\"Resized test shape: {X_test_resized.shape}\")\n",
    "\n",
    "# Step 6: Build the model using MobileNet\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze base model initially\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(9, activation='softmax')(x)  # 9 classes (BCS 1-9)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Step 7: Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(f\"Model input shape: {model.input_shape}\")\n",
    "print(f\"Model output shape: {model.output_shape}\")\n",
    "\n",
    "# Step 8: Add data validation before training\n",
    "print(\"\\nValidating training data...\")\n",
    "print(f\"X_train_resized shape: {X_train_resized.shape}\")\n",
    "print(f\"X_train_resized dtype: {X_train_resized.dtype}\")\n",
    "print(f\"X_train_resized range: [{X_train_resized.min():.3f}, {X_train_resized.max():.3f}]\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_train dtype: {y_train.dtype}\")\n",
    "print(f\"y_train range: [{y_train.min()}, {y_train.max()}]\")\n",
    "\n",
    "# Check for NaN or infinite values\n",
    "if np.isnan(X_train_resized).any():\n",
    "    print(\"WARNING: NaN values found in X_train_resized\")\n",
    "    X_train_resized = np.nan_to_num(X_train_resized)\n",
    "\n",
    "if np.isinf(X_train_resized).any():\n",
    "    print(\"WARNING: Infinite values found in X_train_resized\")\n",
    "    X_train_resized = np.nan_to_num(X_train_resized)\n",
    "\n",
    "# Step 9: Train the model with callbacks for better monitoring\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "try:\n",
    "    print(\"\\nStarting training...\")\n",
    "    history = model.fit(\n",
    "        X_train_resized, y_train,\n",
    "        epochs=30,\n",
    "        batch_size=4,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training failed with error: {e}\")\n",
    "    print(\"Trying with smaller batch size...\")\n",
    "    \n",
    "    # Try with batch size 1 if batch size 4 fails\n",
    "    try:\n",
    "        history = model.fit(\n",
    "            X_train_resized, y_train,\n",
    "            epochs=30,\n",
    "            batch_size=1,\n",
    "            validation_split=0.2,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        print(\"Training completed with batch size 1!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Training failed even with batch size 1: {e2}\")\n",
    "        raise e2\n",
    "\n",
    "# Step 10: Evaluate the model\n",
    "print(\"\\nEvaluating model...\")\n",
    "loss, accuracy = model.evaluate(X_test_resized, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Step 11: Save the model\n",
    "model.save('bcs_prediction_model.h5')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Step 12: Generate predictions and detailed analysis\n",
    "print(\"\\nGenerating predictions...\")\n",
    "y_pred_probs = model.predict(X_test_resized)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "all_labels = list(range(9))\n",
    "cm = confusion_matrix(y_test, y_pred, labels=all_labels)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[f'BCS {i}' for i in range(1, 10)],\n",
    "            yticklabels=[f'BCS {i}' for i in range(1, 10)])\n",
    "plt.xlabel('Predicted BCS')\n",
    "plt.ylabel('Actual BCS')\n",
    "plt.title('Confusion Matrix for BCS Prediction')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test, y_pred,\n",
    "    labels=all_labels,\n",
    "    target_names=[f'BCS {i}' for i in range(1, 10)],\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# Plot training history\n",
    "if 'history' in locals():\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
